{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b9b6b93-b5bb-4be2-9193-9b966063a83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pre-trained model found. Creating a new model architecture.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, LeakyReLU, BatchNormalization, Concatenate, UpSampling2D\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "import os\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "class FaceAgingApp:\n",
    "    def __init__(self, model_path: str = None):\n",
    "        \"\"\"Initialize the face aging application\"\"\"\n",
    "        # Initialize face detection\n",
    "        self.face_cascade = cv2.CascadeClassifier(\n",
    "            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "        )\n",
    "        \n",
    "        # Age groups configuration\n",
    "        self.age_groups = ['20-30', '30-40', '40-50', '50-60', '60-70', '70+']\n",
    "        \n",
    "        # Load or initialize model\n",
    "        self.model = self.load_or_create_model(model_path)\n",
    "\n",
    "    def load_or_create_model(self, model_path: Optional[str]) -> Model:\n",
    "        \"\"\"Load pre-trained model or create a new one if not available\"\"\"\n",
    "        if model_path and os.path.exists(model_path):\n",
    "            print(f\"Loading model from {model_path}\")\n",
    "            return load_model(model_path)\n",
    "        else:\n",
    "            print(\"No pre-trained model found. Creating a new model architecture.\")\n",
    "            return self.build_generator()\n",
    "    \n",
    "    def build_generator(self) -> Model:\n",
    "        \"\"\"Build a generator model for face aging (simplified U-Net)\"\"\"\n",
    "        # Input layers\n",
    "        input_img = Input(shape=(256, 256, 3))\n",
    "        age_cond = Input(shape=(len(self.age_groups),))\n",
    "        \n",
    "        # Expand age condition to spatial dimensions\n",
    "        age_cond_expanded = tf.keras.layers.Lambda(\n",
    "            lambda x: tf.tile(x[:, tf.newaxis, tf.newaxis, :], [1, 256, 256, 1])\n",
    "        )(age_cond)\n",
    "        \n",
    "        # Concatenate image with age condition\n",
    "        x = Concatenate()([input_img, age_cond_expanded])\n",
    "        \n",
    "        # Encoder\n",
    "        def encoder_block(x, filters, kernel_size=4, strides=2, padding='same'):\n",
    "            x = Conv2D(filters, kernel_size, strides=strides, padding=padding)(x)\n",
    "            x = LeakyReLU(alpha=0.2)(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            return x\n",
    "        \n",
    "        # Decoder\n",
    "        def decoder_block(x, skip_input, filters, kernel_size=4, strides=2, padding='same'):\n",
    "            x = UpSampling2D(size=2)(x)\n",
    "            x = Conv2D(filters, kernel_size, strides=1, padding=padding)(x)\n",
    "            x = LeakyReLU(alpha=0.2)(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Concatenate()([x, skip_input])\n",
    "            return x\n",
    "        \n",
    "        # Encoder path\n",
    "        e1 = encoder_block(x, 64)\n",
    "        e2 = encoder_block(e1, 128)\n",
    "        e3 = encoder_block(e2, 256)\n",
    "        e4 = encoder_block(e3, 512)\n",
    "        \n",
    "        # Bottleneck\n",
    "        b = Conv2D(512, 4, strides=2, padding='same')(e4)\n",
    "        b = LeakyReLU(alpha=0.2)(b)\n",
    "        \n",
    "        # Decoder path\n",
    "        d1 = decoder_block(b, e4, 512)\n",
    "        d2 = decoder_block(d1, e3, 256)\n",
    "        d3 = decoder_block(d2, e2, 128)\n",
    "        d4 = decoder_block(d3, e1, 64)\n",
    "        \n",
    "        # Output layer\n",
    "        output = Conv2D(3, 4, strides=1, padding='same', activation='tanh')(d4)\n",
    "        \n",
    "        return Model(inputs=[input_img, age_cond], outputs=output)\n",
    "\n",
    "    def detect_and_align_face(self, image_path: str) -> Optional[np.ndarray]:\n",
    "        \"\"\"Detect and align face from image\"\"\"\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            if img is None:\n",
    "                raise ValueError(\"Could not read image\")\n",
    "                \n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            faces = self.face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "            \n",
    "            if len(faces) == 0:\n",
    "                return None\n",
    "                \n",
    "            (x, y, w, h) = max(faces, key=lambda f: f[2]*f[3])\n",
    "            face = img[y:y+h, x:x+w]\n",
    "            face = cv2.resize(face, (256, 256))\n",
    "            face = (face.astype(np.float32) - 127.5) / 127.5\n",
    "            \n",
    "            return face\n",
    "        except Exception as e:\n",
    "            print(f\"Error in face detection: {e}\")\n",
    "            return None\n",
    "\n",
    "    def predict_age_progression(self, face_image: np.ndarray, target_age_group: str) -> np.ndarray:\n",
    "        \"\"\"Predict age progression for a face image\"\"\"\n",
    "        try:\n",
    "            if face_image is None:\n",
    "                raise ValueError(\"No face image provided\")\n",
    "                \n",
    "            if target_age_group not in self.age_groups:\n",
    "                raise ValueError(f\"Invalid age group. Must be one of {self.age_groups}\")\n",
    "                \n",
    "            input_img = np.expand_dims(face_image, axis=0)\n",
    "            age_idx = self.age_groups.index(target_age_group)\n",
    "            age_cond = np.zeros((1, len(self.age_groups)))\n",
    "            age_cond[0, age_idx] = 1\n",
    "            \n",
    "            aged_face = self.model.predict([input_img, age_cond])\n",
    "            aged_face = ((aged_face[0] + 1) * 127.5).astype(np.uint8)\n",
    "            \n",
    "            return aged_face\n",
    "        except Exception as e:\n",
    "            print(f\"Error in age prediction: {e}\")\n",
    "            return None\n",
    "\n",
    "    def process_image(self, input_image: Image.Image, target_age: str) -> Image.Image:\n",
    "        \"\"\"Process an uploaded image through the age progression pipeline\"\"\"\n",
    "        try:\n",
    "            # Save temporary image\n",
    "            temp_path = \"temp_input.jpg\"\n",
    "            input_image.save(temp_path)\n",
    "            \n",
    "            # Detect and align face\n",
    "            face = self.detect_and_align_face(temp_path)\n",
    "            if face is None:\n",
    "                return \"No face detected. Please upload a clear front-facing photo.\"\n",
    "            \n",
    "            # Generate aged face\n",
    "            aged_face = self.predict_age_progression(face, target_age)\n",
    "            if aged_face is None:\n",
    "                return \"Error generating age progression.\"\n",
    "            \n",
    "            # Convert to PIL Image\n",
    "            aged_pil = Image.fromarray(aged_face)\n",
    "            \n",
    "            # Create comparison\n",
    "            original_resized = Image.open(temp_path).resize((256, 256))\n",
    "            comparison = Image.new('RGB', (512, 256))\n",
    "            comparison.paste(original_resized, (0, 0))\n",
    "            comparison.paste(aged_pil, (256, 0))\n",
    "            \n",
    "            # Clean up\n",
    "            if os.path.exists(temp_path):\n",
    "                os.remove(temp_path)\n",
    "                \n",
    "            return comparison\n",
    "        except Exception as e:\n",
    "            print(f\"Error in processing: {e}\")\n",
    "            return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "def launch_app():\n",
    "    \"\"\"Launch the Gradio interface\"\"\"\n",
    "    app = FaceAgingApp(\"face_aging_model.h5\")\n",
    "    \n",
    "    iface = gr.Interface(\n",
    "        fn=app.process_image,\n",
    "        inputs=[\n",
    "            gr.Image(label=\"Upload Your Photo\", type=\"pil\"),\n",
    "            gr.Dropdown(\n",
    "                choices=app.age_groups,\n",
    "                label=\"Target Age Group\",\n",
    "                value=\"50-60\"\n",
    "            )\n",
    "        ],\n",
    "        outputs=gr.Image(label=\"Age Progression\"),\n",
    "        title=\"AI Face Aging App\",\n",
    "        description=\"Upload your photo to see how you might look at different ages.\",\n",
    "        examples=[\n",
    "            [\"example_young.jpg\", \"40-50\"],\n",
    "            [\"example_middle.jpg\", \"70+\"]\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    iface.launch()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    launch_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "762936c8-60d7-4986-ac28-94c1b2c4026c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/6r/fmh6hr2n4lz1xp35xkc00z0c0000gn/T/ipykernel_4245/1793456848.py:355: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "No GPU detected - running in CPU mode (may be slow)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unable to open shape_predictor_68_face_landmarks.dat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 361\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo GPU detected - running in CPU mode (may be slow)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    360\u001b[0m \u001b[38;5;66;03m# Launch the application\u001b[39;00m\n\u001b[0;32m--> 361\u001b[0m launch_advanced_app()\n",
      "Cell \u001b[0;32mIn[8], line 319\u001b[0m, in \u001b[0;36mlaunch_advanced_app\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Launch the advanced face aging application\"\"\"\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# Initialize with a pre-trained model if available\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m app \u001b[38;5;241m=\u001b[39m AdvancedFaceAger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madvanced_face_aging_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# Create Gradio interface\u001b[39;00m\n\u001b[1;32m    322\u001b[0m iface \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mInterface(\n\u001b[1;32m    323\u001b[0m     fn\u001b[38;5;241m=\u001b[39mapp\u001b[38;5;241m.\u001b[39mprocess_image_pipeline,\n\u001b[1;32m    324\u001b[0m     inputs\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    342\u001b[0m     allow_flagging\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnever\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    343\u001b[0m )\n",
      "Cell \u001b[0;32mIn[8], line 22\u001b[0m, in \u001b[0;36mAdvancedFaceAger.__init__\u001b[0;34m(self, model_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Initialize face detection and alignment\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetector \u001b[38;5;241m=\u001b[39m dlib\u001b[38;5;241m.\u001b[39mget_frontal_face_detector()\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor \u001b[38;5;241m=\u001b[39m dlib\u001b[38;5;241m.\u001b[39mshape_predictor(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape_predictor_68_face_landmarks.dat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfa \u001b[38;5;241m=\u001b[39m face_alignment\u001b[38;5;241m.\u001b[39mFaceAlignment(\n\u001b[1;32m     24\u001b[0m     face_alignment\u001b[38;5;241m.\u001b[39mLandmarksType\u001b[38;5;241m.\u001b[39mTWO_D, \n\u001b[1;32m     25\u001b[0m     flip_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     26\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mtest\u001b[38;5;241m.\u001b[39mis_gpu_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Age configuration\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unable to open shape_predictor_68_face_landmarks.dat"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Concatenate\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "import dlib  # More accurate face detection\n",
    "import face_alignment  # Better alignment\n",
    "from skimage.transform import estimate_transform, warp\n",
    "from typing import Tuple, Optional, List\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "class AdvancedFaceAger:\n",
    "    def __init__(self, model_path: str = None):\n",
    "        \"\"\"Initialize the advanced face aging system\"\"\"\n",
    "        # Initialize face detection and alignment\n",
    "        self.detector = dlib.get_frontal_face_detector()\n",
    "        self.predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "        self.fa = face_alignment.FaceAlignment(\n",
    "            face_alignment.LandmarksType.TWO_D, \n",
    "            flip_input=False,\n",
    "            device='cuda' if tf.test.is_gpu_available() else 'cpu'\n",
    "        )\n",
    "        \n",
    "        # Age configuration\n",
    "        self.age_bins = [\n",
    "            (20, 30), (30, 40), (40, 50), \n",
    "            (50, 60), (60, 70), (70, 80)\n",
    "        ]\n",
    "        self.age_labels = [f\"{start}-{end}\" for start, end in self.age_bins]\n",
    "        \n",
    "        # Load or create model\n",
    "        self.generator = self.load_or_build_model(model_path)\n",
    "        \n",
    "        # Image processing parameters\n",
    "        self.img_size = 256\n",
    "        self.crop_size = 224\n",
    "        self.scale = 1.6\n",
    "\n",
    "    def load_or_build_model(self, model_path: Optional[str]) -> Model:\n",
    "        \"\"\"Load pre-trained model or build a new one with advanced architecture\"\"\"\n",
    "        if model_path and os.path.exists(model_path):\n",
    "            print(f\"Loading pre-trained model from {model_path}\")\n",
    "            return tf.keras.models.load_model(model_path)\n",
    "        \n",
    "        print(\"Building new model with advanced architecture...\")\n",
    "        return self.build_caae_model()\n",
    "\n",
    "    def build_caae_model(self) -> Model:\n",
    "        \"\"\"Build a Conditional Adversarial Autoencoder (CAAE) model\"\"\"\n",
    "        # Image input\n",
    "        img_input = Input(shape=(self.crop_size, self.crop_size, 3))\n",
    "        \n",
    "        # Age condition input (one-hot encoded)\n",
    "        age_input = Input(shape=(len(self.age_bins),))\n",
    "        \n",
    "        # ----------------------------\n",
    "        # Encoder (ResNet-like)\n",
    "        # ----------------------------\n",
    "        def conv_block(x, filters, kernel_size=3, strides=2, use_leaky=True):\n",
    "            x = Conv2D(filters, kernel_size, strides=strides, padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            return LeakyReLU(alpha=0.2)(x) if use_leaky else Activation('relu')(x)\n",
    "        \n",
    "        # Encoder path\n",
    "        e1 = conv_block(img_input, 64)  # 112x112\n",
    "        e2 = conv_block(e1, 128)       # 56x56\n",
    "        e3 = conv_block(e2, 256)       # 28x28\n",
    "        e4 = conv_block(e3, 512)       # 14x14\n",
    "        e5 = conv_block(e4, 512)       # 7x7\n",
    "        \n",
    "        # Flatten and concatenate with age\n",
    "        flattened = Flatten()(e5)\n",
    "        concat = Concatenate()([flattened, age_input])\n",
    "        \n",
    "        # Latent space\n",
    "        latent = Dense(256, activation='relu')(concat)\n",
    "        \n",
    "        # ----------------------------\n",
    "        # Decoder\n",
    "        # ----------------------------\n",
    "        def deconv_block(x, filters, kernel_size=3, strides=2):\n",
    "            x = Conv2DTranspose(filters, kernel_size, strides=strides, padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            return LeakyReLU(alpha=0.2)(x)\n",
    "        \n",
    "        # Reshape and project\n",
    "        projected = Dense(7*7*512)(latent)\n",
    "        reshaped = Reshape((7, 7, 512))(projected)\n",
    "        \n",
    "        # Decoder path\n",
    "        d1 = deconv_block(reshaped, 512)  # 14x14\n",
    "        d2 = deconv_block(d1, 256)        # 28x28\n",
    "        d3 = deconv_block(d2, 128)        # 56x56\n",
    "        d4 = deconv_block(d3, 64)         # 112x112\n",
    "        d5 = Conv2DTranspose(3, 3, strides=2, padding='same', activation='tanh')(d4)  # 224x224\n",
    "        \n",
    "        return Model(inputs=[img_input, age_input], outputs=d5)\n",
    "\n",
    "    def align_face(self, image: np.ndarray) -> Optional[np.ndarray]:\n",
    "        \"\"\"Advanced face alignment using facial landmarks\"\"\"\n",
    "        try:\n",
    "            # Convert to RGB if needed\n",
    "            if len(image.shape) == 2:\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "            elif image.shape[2] == 1:\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "            elif image.shape[2] == 4:\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)\n",
    "            \n",
    "            # Get facial landmarks\n",
    "            landmarks = self.fa.get_landmarks(image)\n",
    "            if not landmarks:\n",
    "                return None\n",
    "                \n",
    "            landmarks = landmarks[0]  # Take first face found\n",
    "            \n",
    "            # Calculate transformation\n",
    "            src_points = np.array([\n",
    "                landmarks[17], landmarks[21], landmarks[22], \n",
    "                landmarks[26], landmarks[36], landmarks[39], \n",
    "                landmarks[42], landmarks[45], landmarks[31], \n",
    "                landmarks[35], landmarks[48], landmarks[54], \n",
    "                landmarks[57], landmarks[8]\n",
    "            ])\n",
    "            \n",
    "            # Estimate similarity transform\n",
    "            tform = estimate_transform(\n",
    "                'similarity',\n",
    "                src_points,\n",
    "                self.get_reference_landmarks()\n",
    "            )\n",
    "            \n",
    "            # Warp and crop face\n",
    "            aligned_face = warp(\n",
    "                image, \n",
    "                tform.inverse, \n",
    "                output_shape=(self.img_size, self.img_size),\n",
    "                mode='constant'\n",
    "            )\n",
    "            \n",
    "            # Crop to final size\n",
    "            margin = (self.img_size - self.crop_size) // 2\n",
    "            aligned_face = aligned_face[\n",
    "                margin:margin+self.crop_size,\n",
    "                margin:margin+self.crop_size\n",
    "            ]\n",
    "            \n",
    "            # Normalize to [-1, 1]\n",
    "            aligned_face = (aligned_face * 255).astype(np.uint8)\n",
    "            aligned_face = (aligned_face.astype(np.float32) - 127.5) / 127.5\n",
    "            \n",
    "            return aligned_face\n",
    "        except Exception as e:\n",
    "            print(f\"Error in face alignment: {e}\")\n",
    "            return None\n",
    "\n",
    "    def get_reference_landmarks(self) -> np.ndarray:\n",
    "        \"\"\"Get reference landmarks for alignment\"\"\"\n",
    "        # Standard reference points based on average face\n",
    "        ref_landmarks = np.array([\n",
    "            [38.2946, 51.6963],  # Left eye left corner\n",
    "            [73.5318, 51.5014],  # Right eye right corner\n",
    "            [56.0252, 71.7366],  # Nose tip\n",
    "            [41.5493, 92.3655],  # Mouth left corner\n",
    "            [70.7299, 92.2041]   # Mouth right corner\n",
    "        ])\n",
    "        \n",
    "        # Scale and center based on our image size\n",
    "        ref_landmarks = ref_landmarks * self.img_size / 112.0\n",
    "        ref_landmarks = ref_landmarks + (self.img_size - self.crop_size) / 2.0\n",
    "        \n",
    "        return ref_landmarks\n",
    "\n",
    "    def predict_aging(self, face_image: np.ndarray, target_age_idx: int) -> np.ndarray:\n",
    "        \"\"\"Predict aging effects with more sophisticated processing\"\"\"\n",
    "        try:\n",
    "            # Create age condition vector\n",
    "            age_cond = np.zeros(len(self.age_bins))\n",
    "            age_cond[target_age_idx] = 1\n",
    "            age_cond = np.expand_dims(age_cond, axis=0)\n",
    "            \n",
    "            # Prepare input\n",
    "            input_img = np.expand_dims(face_image, axis=0)\n",
    "            \n",
    "            # Predict\n",
    "            aged_face = self.generator.predict([input_img, age_cond])[0]\n",
    "            \n",
    "            # Post-processing\n",
    "            aged_face = (aged_face * 127.5 + 127.5).astype(np.uint8)\n",
    "            \n",
    "            # Apply aging artifacts (simulated)\n",
    "            aged_face = self.add_aging_artifacts(aged_face, target_age_idx)\n",
    "            \n",
    "            return aged_face\n",
    "        except Exception as e:\n",
    "            print(f\"Error in age prediction: {e}\")\n",
    "            return None\n",
    "\n",
    "    def add_aging_artifacts(self, image: np.ndarray, age_idx: int) -> np.ndarray:\n",
    "        \"\"\"Add realistic aging artifacts (wrinkles, spots, etc.)\"\"\"\n",
    "        # Convert to float for processing\n",
    "        img_float = image.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Get age parameters\n",
    "        age_start, age_end = self.age_bins[age_idx]\n",
    "        mean_age = (age_start + age_end) / 2\n",
    "        \n",
    "        # 1. Wrinkles (intensity increases with age)\n",
    "        if mean_age > 40:\n",
    "            # Generate Perlin noise for wrinkles\n",
    "            noise = self.generate_perlin_noise(image.shape[:2], scale=0.05)\n",
    "            wrinkle_strength = min(0.15, (mean_age - 40) * 0.005)\n",
    "            img_float = self.apply_wrinkles(img_float, noise, wrinkle_strength)\n",
    "        \n",
    "        # 2. Age spots (appear after 50)\n",
    "        if mean_age > 50:\n",
    "            spot_strength = min(0.1, (mean_age - 50) * 0.002)\n",
    "            img_float = self.apply_age_spots(img_float, spot_strength)\n",
    "        \n",
    "        # 3. Skin tone changes (yellowing)\n",
    "        if mean_age > 60:\n",
    "            yellowing = min(0.08, (mean_age - 60) * 0.002)\n",
    "            img_float[:, :, 0] *= (1 - yellowing * 0.5)  # Reduce blue\n",
    "            img_float[:, :, 1] *= (1 + yellowing * 0.3)  # Increase green slightly\n",
    "        \n",
    "        # Convert back to uint8\n",
    "        return (np.clip(img_float, 0, 1) * 255).astype(np.uint8)\n",
    "\n",
    "    def generate_perlin_noise(self, shape: Tuple[int, int], scale: float = 0.1) -> np.ndarray:\n",
    "        \"\"\"Generate Perlin noise for realistic wrinkles\"\"\"\n",
    "        # Simplified Perlin-like noise\n",
    "        x = np.linspace(0, scale * shape[1], shape[1], endpoint=False)\n",
    "        y = np.linspace(0, scale * shape[0], shape[0], endpoint=False)\n",
    "        xv, yv = np.meshgrid(x, y)\n",
    "        \n",
    "        noise = np.sin(xv) * np.cos(yv) * np.sin(xv + yv)\n",
    "        return (noise - noise.min()) / (noise.max() - noise.min())\n",
    "\n",
    "    def apply_wrinkles(self, image: np.ndarray, noise: np.ndarray, strength: float) -> np.ndarray:\n",
    "        \"\"\"Apply wrinkle effects to image\"\"\"\n",
    "        # Create wrinkle mask (emphasize on forehead and around eyes)\n",
    "        mask = np.zeros_like(image[:, :, 0])\n",
    "        h, w = mask.shape\n",
    "        \n",
    "        # Forehead area\n",
    "        mask[:h//3, :] = 1.0\n",
    "        \n",
    "        # Eye area\n",
    "        mask[h//3:h//2, w//4:3*w//4] = 1.0\n",
    "        \n",
    "        # Combine with noise\n",
    "        wrinkle_mask = noise * mask\n",
    "        \n",
    "        # Apply to image (darken wrinkles)\n",
    "        result = image.copy()\n",
    "        for c in range(3):\n",
    "            result[:, :, c] = np.clip(\n",
    "                result[:, :, c] - wrinkle_mask * strength * (0.8 + 0.2 * np.random.random()),\n",
    "                0, 1\n",
    "            )\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def process_image_pipeline(self, input_image: Image.Image, target_age: str) -> Image.Image:\n",
    "        \"\"\"Complete processing pipeline with better error handling\"\"\"\n",
    "        try:\n",
    "            with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp:\n",
    "                # Save temporary image\n",
    "                input_image.save(tmp.name)\n",
    "                \n",
    "                # Convert to numpy array\n",
    "                img_array = np.array(input_image)\n",
    "                if img_array.shape[-1] == 4:  # RGBA to RGB\n",
    "                    img_array = img_array[..., :3]\n",
    "                \n",
    "                # Align face\n",
    "                aligned_face = self.align_face(img_array)\n",
    "                if aligned_face is None:\n",
    "                    return \"Could not detect or align a face. Please try another image.\"\n",
    "                \n",
    "                # Get target age index\n",
    "                try:\n",
    "                    age_idx = self.age_labels.index(target_age)\n",
    "                except ValueError:\n",
    "                    return f\"Invalid age selection. Must be one of {self.age_labels}\"\n",
    "                \n",
    "                # Predict aging\n",
    "                aged_face = self.predict_aging(aligned_face, age_idx)\n",
    "                if aged_face is None:\n",
    "                    return \"Error generating age progression.\"\n",
    "                \n",
    "                # Convert to PIL Image\n",
    "                aged_pil = Image.fromarray(aged_face)\n",
    "                \n",
    "                # Resize original for comparison\n",
    "                orig_resized = input_image.resize((self.crop_size, self.crop_size))\n",
    "                \n",
    "                # Create comparison image\n",
    "                comparison = Image.new('RGB', (self.crop_size * 2, self.crop_size))\n",
    "                comparison.paste(orig_resized, (0, 0))\n",
    "                comparison.paste(aged_pil, (self.crop_size, 0))\n",
    "                \n",
    "                return comparison\n",
    "        except Exception as e:\n",
    "            print(f\"Error in processing pipeline: {e}\")\n",
    "            return f\"An error occurred: {str(e)}\"\n",
    "        finally:\n",
    "            if os.path.exists(tmp.name):\n",
    "                os.remove(tmp.name)\n",
    "\n",
    "def launch_advanced_app():\n",
    "    \"\"\"Launch the advanced face aging application\"\"\"\n",
    "    # Initialize with a pre-trained model if available\n",
    "    app = AdvancedFaceAger(\"advanced_face_aging_model.h5\")\n",
    "    \n",
    "    # Create Gradio interface\n",
    "    iface = gr.Interface(\n",
    "        fn=app.process_image_pipeline,\n",
    "        inputs=[\n",
    "            gr.Image(label=\"Upload Face Photo\", type=\"pil\"),\n",
    "            gr.Dropdown(\n",
    "                choices=app.age_labels,\n",
    "                label=\"Target Age Group\",\n",
    "                value=\"50-60\"\n",
    "            )\n",
    "        ],\n",
    "        outputs=gr.Image(label=\"Age Progression Comparison\"),\n",
    "        title=\"Advanced AI Face Aging\",\n",
    "        description=(\n",
    "            \"Upload a clear front-facing photo to see realistic age progression. \"\n",
    "            \"For best results, use a well-lit photo with neutral expression.\"\n",
    "        ),\n",
    "        examples=[\n",
    "            [\"example_young.jpg\", \"40-50\"],\n",
    "            [\"example_adult.jpg\", \"70-80\"]\n",
    "        ],\n",
    "        allow_flagging=\"never\"\n",
    "    )\n",
    "    \n",
    "    # Launch with better configuration\n",
    "    iface.launch(\n",
    "        server_name=\"0.0.0.0\",\n",
    "        server_port=7860,\n",
    "        enable_queue=True,\n",
    "        share=False\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Check for GPU availability\n",
    "    if tf.test.is_gpu_available():\n",
    "        print(\"GPU available - using GPU acceleration\")\n",
    "    else:\n",
    "        print(\"No GPU detected - running in CPU mode (may be slow)\")\n",
    "    \n",
    "    # Launch the application\n",
    "    launch_advanced_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40cb21d7-4c3e-4f6d-a365-848a42669d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU detected - running in CPU mode (may be slow)\n",
      "Failed to launch application: dlib shape predictor file not found. Please download from: http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
      "Possible solutions:\n",
      "1. Make sure you've downloaded shape_predictor_68_face_landmarks.dat\n",
      "2. Check that all required packages are installed\n",
      "3. Verify you have proper permissions to access the model files\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Concatenate, Conv2D, Conv2DTranspose, LeakyReLU, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "import dlib\n",
    "import face_alignment\n",
    "from skimage.transform import estimate_transform, warp\n",
    "from typing import Tuple, Optional, List\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "class AdvancedFaceAger:\n",
    "    def __init__(self, model_path: str = None):\n",
    "        \"\"\"Initialize the advanced face aging system\"\"\"\n",
    "        # Initialize face detection and alignment\n",
    "        self.detector = dlib.get_frontal_face_detector()\n",
    "        \n",
    "        # Load shape predictor (updated path handling)\n",
    "        predictor_path = \"shape_predictor_68_face_landmarks.dat\"\n",
    "        if not os.path.exists(predictor_path):\n",
    "            raise FileNotFoundError(\n",
    "                \"dlib shape predictor file not found. \"\n",
    "                \"Please download from: http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\"\n",
    "            )\n",
    "        self.predictor = dlib.shape_predictor(predictor_path)\n",
    "        \n",
    "        # Initialize face alignment with GPU check\n",
    "        gpu_available = len(tf.config.list_physical_devices('GPU')) > 0\n",
    "        self.fa = face_alignment.FaceAlignment(\n",
    "            face_alignment.LandmarksType.TWO_D, \n",
    "            flip_input=False,\n",
    "            device='cuda' if gpu_available else 'cpu'\n",
    "        )\n",
    "        \n",
    "        # Age configuration\n",
    "        self.age_bins = [\n",
    "            (20, 30), (30, 40), (40, 50), \n",
    "            (50, 60), (60, 70), (70, 80)\n",
    "        ]\n",
    "        self.age_labels = [f\"{start}-{end}\" for start, end in self.age_bins]\n",
    "        \n",
    "        # Load or create model\n",
    "        self.generator = self.load_or_build_model(model_path)\n",
    "        \n",
    "        # Image processing parameters\n",
    "        self.img_size = 256\n",
    "        self.crop_size = 224\n",
    "        self.scale = 1.6\n",
    "\n",
    "    # [Rest of your class methods remain the same...]\n",
    "\n",
    "def launch_advanced_app():\n",
    "    \"\"\"Launch the advanced face aging application\"\"\"\n",
    "    try:\n",
    "        # Check for GPU availability\n",
    "        gpu_available = len(tf.config.list_physical_devices('GPU')) > 0\n",
    "        if gpu_available:\n",
    "            print(\"GPU available - using GPU acceleration\")\n",
    "            # Configure GPU memory growth\n",
    "            gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        else:\n",
    "            print(\"No GPU detected - running in CPU mode (may be slow)\")\n",
    "        \n",
    "        # Initialize with a pre-trained model if available\n",
    "        app = AdvancedFaceAger(\"advanced_face_aging_model.h5\")\n",
    "        \n",
    "        # Create Gradio interface\n",
    "        iface = gr.Interface(\n",
    "            fn=app.process_image_pipeline,\n",
    "            inputs=[\n",
    "                gr.Image(label=\"Upload Face Photo\", type=\"pil\"),\n",
    "                gr.Dropdown(\n",
    "                    choices=app.age_labels,\n",
    "                    label=\"Target Age Group\",\n",
    "                    value=\"50-60\"\n",
    "                )\n",
    "            ],\n",
    "            outputs=gr.Image(label=\"Age Progression Comparison\"),\n",
    "            title=\"Advanced AI Face Aging\",\n",
    "            description=(\n",
    "                \"Upload a clear front-facing photo to see realistic age progression. \"\n",
    "                \"For best results, use a well-lit photo with neutral expression.\"\n",
    "            ),\n",
    "            allow_flagging=\"never\"\n",
    "        )\n",
    "        \n",
    "        # Launch with better configuration\n",
    "        iface.launch(\n",
    "            server_name=\"0.0.0.0\",\n",
    "            server_port=7860,\n",
    "            enable_queue=True,\n",
    "            share=False\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to launch application: {str(e)}\")\n",
    "        print(\"Possible solutions:\")\n",
    "        print(\"1. Make sure you've downloaded shape_predictor_68_face_landmarks.dat\")\n",
    "        print(\"2. Check that all required packages are installed\")\n",
    "        print(\"3. Verify you have proper permissions to access the model files\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    launch_advanced_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf2168-b3e4-404b-a99d-348febf8de4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
